# -*- coding: utf-8 -*-
"""DistilBERT的文学文本情感智能分析系统设计与应用.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15PWgtDSKoo7D3Mr_mmsR84CQVfn30C-_
"""

!pip install transformers nltk spacy tqdm pandas matplotlib seaborn
!python -m spacy download en_core_web_md

"""## 步骤1：环境准备与基础设置"""

import os
import nltk
import spacy
import pandas as pd
from transformers import pipeline
import matplotlib.pyplot as plt
import seaborn as sns
import re
from tqdm import tqdm
import numpy as np
from collections import Counter
import warnings
warnings.filterwarnings('ignore')

# 下载必要的NLTK资源
nltk.download('punkt')
nltk.download('punkt_tab')
nltk.download('stopwords')

# 加载spaCy模型
try:
    nlp = spacy.load('en_core_web_md')
except:
    # 如果模型未安装，先安装再加载
    os.system('python -m spacy download en_core_web_md')
    nlp = spacy.load('en_core_web_md')

print("加载情感分析模型...")
# 使用HuggingFace的预训练模型
sentiment_analyzer = pipeline('sentiment-analysis')
emotion_analyzer = pipeline('text-classification',
                           model='bhadresh-savani/distilbert-base-uncased-emotion')

"""# 书籍排序辅助函数"""
def extract_book_number(book_name):
    """从书名中提取数字编号用于排序"""
    # 移除.txt后缀（如果有）
    clean_name = book_name.replace('.txt', '')
    match = re.match(r'(\d+)\s', clean_name)
    if match:
        return int(match.group(1))
    return 999  # 如果没有数字前缀，则放到最后

"""# 步骤2：文本预处理函数"""

def preprocess_corpus(corpus_directory):
    """Process all text files in the Morrison novel corpus"""
    print(f"Starting corpus processing: {corpus_directory}")
    texts = []

    for filename in tqdm(os.listdir(corpus_directory), desc="Processing files"):
        if filename.endswith('.txt'):
            filepath = os.path.join(corpus_directory, filename)
            with open(filepath, 'r', encoding='utf-8', errors='ignore') as file:
                lines = file.readlines()

                # 过滤掉行号
                cleaned_lines = []
                for line in lines:
                    # 处理带有行号的行
                    line = line.strip()
                    if line:
                        # 尝试匹配行首的数字
                        match = re.match(r'^\d+\s+(.+)$', line)
                        if match:
                            cleaned_lines.append(match.group(1))
                        else:
                            cleaned_lines.append(line)

                # 将清理后的文本连接成段落
                text = ' '.join(cleaned_lines)

                # 分割为段落进行更精细的分析
                paragraphs = re.split(r'\n\s*\n', text)
                paragraphs = [p.strip() for p in paragraphs if p.strip()]

                # 如果段落很少，可能说明文本没有明确的段落分割
                # 在这种情况下，尝试按句子或固定长度分割
                if len(paragraphs) < 5:
                    # 按句子分割
                    sentences = nltk.sent_tokenize(text)
                    # 将句子重新组合成适当大小的段落
                    paragraphs = []
                    current_paragraph = []
                    current_length = 0

                    for sentence in sentences:
                        current_paragraph.append(sentence)
                        current_length += len(sentence)

                        if current_length > 500:  # 每个段落大约500个字符
                            paragraphs.append(' '.join(current_paragraph))
                            current_paragraph = []
                            current_length = 0

                    if current_paragraph:
                        paragraphs.append(' '.join(current_paragraph))

                # 添加书名和段落
                for i, para in enumerate(paragraphs):
                    if len(para) > 100:  # 忽略太短的段落
                        texts.append({
                            'book': filename,
                            'paragraph_id': i,
                            'content': para
                        })

    df = pd.DataFrame(texts)
    print(f"Processing complete, extracted {len(df)} text paragraphs")
    return df

"""# 步骤3：情感分析函数"""

def analyze_text_emotions(text, max_length=500):
    """Analyze text emotions, handling long texts"""
    if len(text) <= max_length:
        try:
            sentiment = sentiment_analyzer(text)[0]
            emotion = emotion_analyzer(text)[0]
            return {
                'sentiment': sentiment['label'],
                'sentiment_score': sentiment['score'],
                'emotion': emotion['label'],
                'emotion_score': emotion['score']
            }
        except Exception as e:
            return {
                'sentiment': 'ERROR',
                'sentiment_score': 0,
                'emotion': 'ERROR',
                'emotion_score': 0
            }
    else:
        # 对于长文本，分成多个片段进行分析
        segments = [text[i:i+max_length] for i in range(0, len(text), max_length)]
        results = []

        for segment in segments:
            try:
                sentiment = sentiment_analyzer(segment)[0]
                emotion = emotion_analyzer(segment)[0]
                results.append({
                    'sentiment': sentiment['label'],
                    'sentiment_score': sentiment['score'],
                    'emotion': emotion['label'],
                    'emotion_score': emotion['score']
                })
            except:
                pass

        if not results:
            return {
                'sentiment': 'UNKNOWN',
                'sentiment_score': 0,
                'emotion': 'UNKNOWN',
                'emotion_score': 0
            }

        # 汇总结果
        sentiments = [r['sentiment'] for r in results]
        emotions = [r['emotion'] for r in results]

        # 取最常见的情感
        dominant_sentiment = Counter(sentiments).most_common(1)[0][0]
        dominant_emotion = Counter(emotions).most_common(1)[0][0]

        # 计算平均分数
        avg_sentiment_score = sum(r['sentiment_score'] for r in results) / len(results)
        avg_emotion_score = sum(r['emotion_score'] for r in results) / len(results)

        return {
            'sentiment': dominant_sentiment,
            'sentiment_score': avg_sentiment_score,
            'emotion': dominant_emotion,
            'emotion_score': avg_emotion_score
        }

"""# 步骤4：角色情感分析函数"""

def extract_character_emotions(text):
    """Extract characters mentioned in the text and their associated emotions"""
    doc = nlp(text[:10000])  # 限制长度以避免处理太大的文本

    # 提取人名实体
    characters = {}
    for ent in doc.ents:
        if ent.label_ == 'PERSON':
            characters[ent.text] = characters.get(ent.text, 0) + 1

    # 只保留频繁出现的角色（可能是主要角色）
    main_characters = {char: count for char, count in characters.items()
                      if count >= 2}  # 至少出现2次

    # 为主要角色创建情感关联
    character_emotions = {}
    for character in main_characters:
        # 找出提到该角色的句子
        character_contexts = []
        for sent in doc.sents:
            sent_text = sent.text
            if character in sent_text:
                # 提取上下文（当前句子加前后句子，如果有的话）
                context = sent_text
                character_contexts.append(context)

        # 分析这些上下文的情感
        if character_contexts:
            # 合并上下文为一个文本进行分析
            combined_context = ' '.join(character_contexts[:5])  # 限制样本数量
            try:
                emotion_result = emotion_analyzer(combined_context)[0]

                character_emotions[character] = {
                    'emotion': emotion_result['label'],
                    'score': emotion_result['score'],
                    'contexts': character_contexts[:3]  # 只保存前3个上下文示例
                }
            except:
                pass

    return character_emotions

"""# 步骤5：情感转换分析函数"""

def analyze_emotion_transitions(df):
    """Analyze emotion transition patterns"""
    # 按照书籍编号顺序进行排序
    df_sorted = df.copy()
    # 先按书名的数字编号排序，再按段落ID排序
    df_sorted['book_num'] = df_sorted['book'].apply(extract_book_number)
    df_sorted = df_sorted.sort_values(['book_num', 'paragraph_id'])

    # 创建情感转换序列
    transitions = []
    previous_book = None
    previous_emotion = None

    for _, row in df_sorted.iterrows():
        current_book = row['book']
        current_emotion = row['emotion_analysis']['emotion']

        # 只在同一本书内分析转换
        if previous_book == current_book and previous_emotion is not None:
            transitions.append((previous_emotion, current_emotion))

        previous_book = current_book
        previous_emotion = current_emotion

    # 计算转换频率
    transition_counts = Counter(transitions)

    # 创建转换矩阵
    emotions = sorted(set([t[0] for t in transitions] + [t[1] for t in transitions]))
    transition_matrix = pd.DataFrame(0, index=emotions, columns=emotions)

    for (from_emotion, to_emotion), count in transition_counts.items():
        transition_matrix.loc[from_emotion, to_emotion] = count

    # 行归一化，计算转换概率
    row_sums = transition_matrix.sum(axis=1)
    transition_probs = transition_matrix.div(row_sums, axis=0).fillna(0)

    return transition_probs

"""# 步骤6：情感关键词提取函数"""

def extract_emotion_keywords(df, emotion_column='emotion'):
    """Extract keywords associated with various emotions"""
    emotion_keywords = {}

    # 对每种情感分别处理
    emotions = df[emotion_column].unique()

    for emotion in emotions:
        # 提取具有该情感的所有文本
        emotion_texts = df[df[emotion_column] == emotion]['content'].tolist()

        # 处理这些文本以提取关键词
        all_words = []
        for text in emotion_texts:
            doc = nlp(text)
            # 提取名词、形容词和动词
            words = [token.lemma_.lower() for token in doc
                   if token.is_alpha and not token.is_stop
                   and token.pos_ in ('NOUN', 'ADJ', 'VERB')]
            all_words.extend(words)

        # 计算关键词频率
        word_counts = Counter(all_words)
        common_words = word_counts.most_common(20)

        emotion_keywords[emotion] = common_words

    return emotion_keywords

"""# 步骤7：情感可视化函数 - 书籍情感分布"""

def visualize_book_emotions(df):
    """Visualize emotion distribution across books"""
    # 直接从原始数据提取情感数据，避免中间处理错误
    emotion_data = []
    for _, row in df.iterrows():
        book = row['book'].replace('.txt', '')
        emotion = row['emotion_analysis']['emotion']
        emotion_data.append({'book': book, 'emotion': emotion})

    emotion_df = pd.DataFrame(emotion_data)

    # 统计每本书中的情感总数
    book_totals = emotion_df.groupby('book').size()

    # 获取所有唯一的情感标签并排序
    unique_emotions = sorted(emotion_df['emotion'].unique())

    # 如果情感类型太多（超过7种），只保留最常见的6种，其余归为"Others"
    if len(unique_emotions) > 7:
        # 计算每种情感的总频率
        emotion_counts = emotion_df['emotion'].value_counts()
        top_emotions = emotion_counts.nlargest(6).index.tolist()

        # 将非主要情感标为"Others"
        emotion_df['emotion'] = emotion_df['emotion'].apply(
            lambda x: x if x in top_emotions else 'Others')

    # 创建一个颜色映射，确保每种情感有一个一致的颜色
    # 使用易于区分的颜色方案
    color_map = {
        'joy': '#FFD700',        # 金色
        'sadness': '#1E90FF',    # 道奇蓝
        'anger': '#FF4500',      # 橙红色
        'fear': '#800080',       # 紫色
        'love': '#FF69B4',       # 粉红色
        'surprise': '#00FF7F',   # 春绿色
        'Others': '#A9A9A9'      # 深灰色
    }

    # 添加额外的情感颜色
    extra_colors = {
        'disgust': '#8B4513',    # 棕色
        'contempt': '#4682B4',   # 钢蓝色
        'shame': '#CD5C5C',      # 印度红
        'guilt': '#6A5ACD'       # 板岩蓝
    }
    color_map.update(extra_colors)

    # 计算情感百分比
    emotion_counts = emotion_df.groupby(['book', 'emotion']).size().unstack().fillna(0)

    # 确保所有列都存在，如果没有则添加为0
    all_emotions = sorted(emotion_df['emotion'].unique())
    for emotion in all_emotions:
        if emotion not in emotion_counts.columns:
            emotion_counts[emotion] = 0

    # 将计数转换为百分比
    emotion_percentages = emotion_counts.copy()
    for col in emotion_counts.columns:
        emotion_percentages[col] = emotion_counts[col] / emotion_counts.sum(axis=1) * 100

    # ===== 按书籍编号排序 =====
    sorted_books = sorted(emotion_percentages.index, key=extract_book_number)
    emotion_percentages = emotion_percentages.loc[sorted_books]

    # 创建图形和坐标轴，调整大小并为图例留出空间
    fig, ax = plt.subplots(figsize=(15, 10))

    # 获取排序后的情感类型列表（确保Others在最后）
    ordered_emotions = sorted([e for e in emotion_percentages.columns if e != 'Others'])
    if 'Others' in emotion_percentages.columns:
        ordered_emotions.append('Others')

    # 提取颜色列表，确保顺序与情感列表匹配
    colors = [color_map.get(emotion, '#333333') for emotion in ordered_emotions]

    # 创建堆叠条形图，使用排序后的情感和对应的颜色
    emotion_percentages[ordered_emotions].plot(
        kind='bar',
        stacked=True,
        color=colors,
        ax=ax
    )

    # 设置图表标题和标签
    ax.set_title('Emotion Distribution Across Toni Morrison\'s Works', fontsize=16)
    ax.set_ylabel('Percentage of Paragraphs (%)', fontsize=14)
    ax.set_xlabel('Book Title', fontsize=14)
    ax.set_ylim(0, 105)  # 确保y轴最大值不超过100%

    # 设置x轴标签旋转
    plt.xticks(rotation=45, ha='right', fontsize=12)
    plt.yticks(fontsize=12)

    # 添加网格线
    ax.grid(axis='y', linestyle='--', alpha=0.3)

    # 将图例放在图表右侧，避免遮挡数据
    ax.legend(title='Emotion Type',
              title_fontsize=14,
              fontsize=12,
              loc='center left',  # 左中位置
              bbox_to_anchor=(1.01, 0.5),  # 紧靠图表右侧
              frameon=True)  # 添加边框

    # 添加样本大小标签
    for i, book in enumerate(emotion_percentages.index):
        book_total = book_totals[book]
        ax.text(i, 5, f'n={book_total}', ha='center', fontsize=10, color='black',
                bbox=dict(facecolor='white', alpha=0.7, boxstyle='round,pad=0.2'))

    # 调整布局，为图例预留空间
    plt.tight_layout()
    plt.subplots_adjust(right=0.85)  # 减小右边界，为图例腾出空间

    return emotion_percentages

"""# 步骤8：情感可视化函数 - 单本书情感流动"""

def visualize_emotion_flow(df, book_name):
    """Visualize emotion flow for a specific book"""
    # 过滤特定书籍的数据
    book_df = df[df['book'] == book_name].sort_values('paragraph_id')

    # 提取情感序列
    emotions = [item['emotion'] for item in book_df['emotion_analysis']]
    scores = [item['emotion_score'] for item in book_df['emotion_analysis']]

    # 为每种情感分配一个数值，以便可视化
    unique_emotions = sorted(set(emotions))
    emotion_values = {emotion: i for i, emotion in enumerate(unique_emotions)}

    # 转换情感为数值
    emotion_nums = [emotion_values[e] for e in emotions]

    # 创建情感流动图
    plt.figure(figsize=(15, 8))

    # 处理书名显示（去掉.txt后缀）
    display_name = book_name.replace('.txt', '')

    # 绘制情感变化曲线
    plt.subplot(2, 1, 1)
    plt.plot(emotion_nums, 'o-', alpha=0.7)
    plt.yticks(list(emotion_values.values()), list(emotion_values.keys()))
    plt.title(f'Emotion Flow in {display_name}')
    plt.xlabel('Paragraph Index')
    plt.ylabel('Emotion Type')
    plt.grid(True, alpha=0.3)

    # 绘制情感强度曲线
    plt.subplot(2, 1, 2)
    plt.plot(scores, 'r-', alpha=0.8)
    plt.title(f'Emotion Intensity in {display_name}')
    plt.xlabel('Paragraph Index')
    plt.ylabel('Emotion Intensity Score')
    plt.grid(True, alpha=0.3)

    plt.tight_layout()

    # 返回情感序列，以便进一步分析
    return {'emotions': emotions, 'scores': scores}

"""# 步骤9：主分析执行函数"""

def run_morrison_analysis(corpus_path):
    """Run complete emotion analysis on Morrison's works"""
    print("Starting Toni Morrison novels emotion analysis...")

    # 1. 处理语料库
    corpus_df = preprocess_corpus(corpus_path)
    print(f"Corpus processing complete, total of {len(corpus_df)} paragraphs")

    # 2. 情感分析
    print("Starting emotion analysis, this may take a few minutes...")
    # 使用样本数据进行测试，可以根据需要调整
    sample_size = min(len(corpus_df), 500)  # 调整样本大小
    sample_df = corpus_df.sample(sample_size, random_state=42)

    # 情感分析，使用进度条
    print("Analyzing paragraph emotions...")
    sample_df['emotion_analysis'] = [
        analyze_text_emotions(text) for text in tqdm(sample_df['content'], desc="Emotion Analysis")
    ]

    # 提取情感作为单独的列，便于后续分析
    sample_df['sentiment'] = sample_df['emotion_analysis'].apply(lambda x: x['sentiment'])
    sample_df['emotion'] = sample_df['emotion_analysis'].apply(lambda x: x['emotion'])

    # 3. 分析书籍间的情感分布
    print("Analyzing emotion distribution across books...")
    emotion_counts = visualize_book_emotions(sample_df)
    plt.savefig('morrison_emotion_distribution.png')
    print("Emotion distribution chart saved as morrison_emotion_distribution.png")

    # 4. 分析情感转换模式
    print("Analyzing emotion transition patterns...")
    transition_probs = analyze_emotion_transitions(sample_df)

    # 可视化转换概率
    plt.figure(figsize=(12, 10))
    ax = sns.heatmap(transition_probs, annot=True, cmap='YlGnBu', fmt='.2f')
    plt.title('Emotion Transition Probabilities in Toni Morrison\'s Works', fontsize=16)
    plt.tight_layout()
    plt.savefig('morrison_emotion_transitions.png')
    print("Emotion transition matrix saved as morrison_emotion_transitions.png")

    # 5. 提取与情感相关的关键词
    print("Extracting emotion keywords...")
    emotion_keywords = extract_emotion_keywords(sample_df, 'emotion')

    # 可视化关键词
    for emotion, keywords in emotion_keywords.items():
        plt.figure(figsize=(10, 6))
        words, counts = zip(*keywords)
        sns.barplot(x=list(counts), y=list(words))
        plt.title(f"Keywords Associated with '{emotion}'")
        plt.xlabel('Frequency')
        plt.ylabel('Keywords')
        plt.savefig(f'morrison_keywords_{emotion}.png')
    print("Emotion keyword charts saved")

    # 6. 分析特定书籍的情感流动
    print("Analyzing emotion flow in each book...")
    # 按照书籍编号排序处理书籍
    sorted_books = sorted(sample_df['book'].unique(), key=extract_book_number)
    for book in sorted_books:
        if len(sample_df[sample_df['book'] == book]) > 10:  # 确保有足够的段落
            print(f"Analyzing emotion flow in {book}...")
            flow_data = visualize_emotion_flow(sample_df, book)
            plt.savefig(f'morrison_emotion_flow_{book.replace(" ", "_").replace(".txt", "")}.png')
    print("Emotion flow charts saved")

    # 7. 分析角色情感
    print("Analyzing character emotion associations...")
    # 选择一些样本文本进行角色情感分析
    character_sample = sample_df.sample(min(30, len(sample_df)))

    all_character_emotions = {}
    for _, row in tqdm(character_sample.iterrows(), desc="Character Emotion Analysis", total=len(character_sample)):
        text = row['content']
        book = row['book']

        character_emotions = extract_character_emotions(text)

        # 将角色情感与书籍关联
        for character, data in character_emotions.items():
            if character not in all_character_emotions:
                all_character_emotions[character] = {'books': set(), 'emotions': []}

            all_character_emotions[character]['books'].add(book)
            all_character_emotions[character]['emotions'].append(data['emotion'])

    # 输出角色情感分析结果
    character_summary = []
    for character, data in all_character_emotions.items():
        if len(data['emotions']) >= 2:  # 至少有2个情感记录
            emotion_counter = Counter(data['emotions'])
            dominant_emotion = emotion_counter.most_common(1)[0][0]

            character_summary.append({
                'character': character,
                'books': ', '.join(data['books']),
                'dominant_emotion': dominant_emotion,
                'emotion_count': len(data['emotions'])
            })

    character_df = pd.DataFrame(character_summary)
    if len(character_df) > 0:
        character_df.to_csv('morrison_character_emotions.csv', index=False)
        print("Character emotion analysis results saved as morrison_character_emotions.csv")

    print("Morrison novel emotion analysis complete!")
    return sample_df

"""# 步骤10：执行分析"""

# 运行完整分析
corpus_path = "/content/drive/MyDrive/亚姐/莫里森_11_txt"
result_df = run_morrison_analysis(corpus_path)

"""# Test"""

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from collections import Counter
import random
import re

# 书籍排序辅助函数
def extract_book_number(book_name):
    """从书名中提取数字编号用于排序"""
    # 移除.txt后缀（如果有）
    clean_name = book_name.replace('.txt', '')
    match = re.match(r'(\d+)\s', clean_name)
    if match:
        return int(match.group(1))
    return 999  # 如果没有数字前缀，则放到最后

# 创建测试数据
def create_morrison_test_data():
    # 模拟11本书，按不同顺序排列以测试排序功能
    books = [
        '9 A Mercy.txt',
        '4 Tar Baby.txt',
        '11 God Help the Child.txt',
        '1 The Bluest Eye.txt',
        '6 Jazz.txt',
        '2 Sula.txt',
        '10 Home.txt',
        '3 Song of Solomon.txt',
        '7 Paradise.txt',
        '5 Beloved.txt',
        '8 Love.txt'
    ]

    # 使用标准的情感标签
    emotions = ['joy', 'sadness', 'anger', 'fear', 'love', 'surprise']

    # 为每本书创建带有情感分析的段落
    test_data = []

    for book in books:
        # 为每本书创建20-50个段落
        num_paragraphs = random.randint(20, 50)

        # 每本书都有不同的情感分布偏好
        if '1 The Bluest' in book:
            weights = [0.1, 0.4, 0.2, 0.1, 0.1, 0.1]  # 偏向悲伤
        elif '5 Beloved' in book:
            weights = [0.1, 0.3, 0.3, 0.2, 0.05, 0.05]  # 悲伤和愤怒
        elif '3 Song of Solomon' in book:
            weights = [0.25, 0.2, 0.1, 0.1, 0.25, 0.1]  # 喜悦和爱
        elif '9 A Mercy' in book:
            weights = [0.1, 0.1, 0.4, 0.2, 0.1, 0.1]  # 偏向愤怒
        elif '11 God Help' in book:
            weights = [0.15, 0.15, 0.15, 0.15, 0.3, 0.1]  # 偏向爱
        else:
            weights = [1/6] * 6  # 平均分布

        for i in range(num_paragraphs):
            # 随机选择一种情感，基于权重
            emotion = random.choices(emotions, weights=weights, k=1)[0]

            # 创建情感分析结果
            emotion_analysis = {
                'sentiment': 'POSITIVE' if emotion in ['joy', 'love', 'surprise'] else 'NEGATIVE',
                'sentiment_score': random.uniform(0.7, 0.95),
                'emotion': emotion,
                'emotion_score': random.uniform(0.7, 0.95)
            }

            # 添加到测试数据
            test_data.append({
                'book': book,
                'paragraph_id': i,
                'content': f"Test paragraph {i} with {emotion} emotion.",
                'emotion_analysis': emotion_analysis
            })

    return pd.DataFrame(test_data)

# 可视化函数 - 修改后包含排序功能，并将图例移至图表右侧
def visualize_book_emotions_sorted(df):
    """按数字编号排序可视化书籍情感分布"""
    # 准备数据
    emotion_data = []
    for _, row in df.iterrows():
        book = row['book'].replace('.txt', '')
        emotion = row['emotion_analysis']['emotion']
        emotion_data.append({'book': book, 'emotion': emotion})

    emotion_df = pd.DataFrame(emotion_data)

    # 统计每本书中的情感总数
    book_totals = emotion_df.groupby('book').size()

    # 计算情感百分比
    emotion_counts = emotion_df.groupby(['book', 'emotion']).size().unstack().fillna(0)

    # 将计数转换为百分比
    emotion_percentages = emotion_counts.copy()
    for col in emotion_counts.columns:
        emotion_percentages[col] = emotion_counts[col] / emotion_counts.sum(axis=1) * 100

    # ===== 关键修改：按书籍编号排序 =====
    sorted_books = sorted(emotion_percentages.index, key=extract_book_number)
    emotion_percentages = emotion_percentages.loc[sorted_books]

    # 创建颜色映射
    color_map = {
        'joy': '#FFD700',       # 金色
        'sadness': '#1E90FF',   # 道奇蓝
        'anger': '#FF4500',     # 橙红色
        'fear': '#800080',      # 紫色
        'love': '#FF69B4',      # 粉红色
        'surprise': '#00FF7F',  # 春绿色
    }

    # 创建图形和坐标轴，调整大小并为图例留出空间
    fig, ax = plt.subplots(figsize=(15, 8))

    # 获取排序后的情感类型列表
    ordered_emotions = sorted(emotion_percentages.columns)

    # 提取颜色列表，确保顺序与情感列表匹配
    colors = [color_map.get(emotion, '#333333') for emotion in ordered_emotions]

    # 创建堆叠条形图，使用排序后的情感和对应的颜色
    emotion_percentages[ordered_emotions].plot(
        kind='bar',
        stacked=True,
        color=colors,
        ax=ax
    )

    # 设置图表标题和标签
    ax.set_title('Emotion Distribution Across Toni Morrison\'s Works (Ordered by Book Number)', fontsize=16)
    ax.set_ylabel('Percentage of Paragraphs (%)', fontsize=14)
    ax.set_xlabel('Book Title', fontsize=14)
    ax.set_ylim(0, 105)  # 确保y轴最大值不超过100%

    # 设置x轴标签旋转
    plt.xticks(rotation=45, ha='right', fontsize=12)
    plt.yticks(fontsize=12)

    # 添加网格线
    ax.grid(axis='y', linestyle='--', alpha=0.3)

    # 将图例放在图表右侧，与图表不重叠，类似示例图片
    ax.legend(title='Emotion Type',
              title_fontsize=14,
              fontsize=12,
              loc='center left',  # 左中位置
              bbox_to_anchor=(1.01, 0.5),  # 紧靠图表右侧
              frameon=True)  # 添加边框

    # 添加样本大小标签
    for i, book in enumerate(emotion_percentages.index):
        book_total = book_totals[book]
        ax.text(i, 5, f'n={book_total}', ha='center', fontsize=10, color='black',
                bbox=dict(facecolor='white', alpha=0.7, boxstyle='round,pad=0.2'))

    # 调整布局，为图例预留空间
    plt.tight_layout()
    # 额外调整右侧边距，确保图例完全可见
    plt.subplots_adjust(right=0.85)

    return emotion_percentages

# 运行测试并生成排序后的可视化
def test_book_sorting():
    print("创建测试数据...")
    test_df = create_morrison_test_data()

    print(f"创建了{len(test_df)}条数据，跨越{test_df['book'].nunique()}本书")

    # 打印每本书的数据量
    book_counts = test_df.groupby('book').size()
    print("\n每本书的段落数：")
    for book, count in book_counts.items():
        print(f"{book}: {count}段落")

    print("\n生成按书籍编号排序的情感分布图...")
    emotion_percentages = visualize_book_emotions_sorted(test_df)

    plt.savefig('morrison_books_sorted_by_number.png', bbox_inches='tight')
    plt.show()

    print("测试完成！已生成排序后的图表 'morrison_books_sorted_by_number.png'")

    # 打印排序后的情感分布百分比
    print("\n排序后的情感分布百分比（按书籍编号）：")
    print(emotion_percentages.round(1))

    return "排序测试成功完成"

# 执行测试
test_result = test_book_sorting()
print(test_result)

# 修复的测试代码
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from collections import Counter
import random
import matplotlib.colors as mcolors

# 创建测试数据
def create_test_data():
    # 模拟6本书，每本书有不同的情感分布
    books = ['1 The Bluest Eye.txt', '2 Sula.txt', '3 Song of Solomon.txt',
             '4 Tar Baby.txt', '5 Beloved.txt', '6 Jazz.txt']

    # 使用标准的情感标签，而不是单字符
    emotions = ['joy', 'sadness', 'anger', 'fear', 'love', 'surprise']

    # 为每本书创建带有情感分析的段落
    test_data = []

    for book in books:
        # 为每本书创建30-100个段落
        num_paragraphs = random.randint(30, 100)

        # 每本书都有不同的情感分布偏好
        if 'Bluest' in book:
            weights = [0.1, 0.4, 0.2, 0.1, 0.1, 0.1]  # 偏向悲伤
        elif 'Beloved' in book:
            weights = [0.1, 0.3, 0.3, 0.2, 0.05, 0.05]  # 悲伤和愤怒
        elif 'Solomon' in book:
            weights = [0.25, 0.2, 0.1, 0.1, 0.25, 0.1]  # 喜悦和爱
        else:
            weights = [1/6] * 6  # 平均分布

        for i in range(num_paragraphs):
            # 随机选择一种情感，基于权重
            emotion = random.choices(emotions, weights=weights, k=1)[0]

            # 偶尔添加一些罕见的情感，测试"Others"分类
            if random.random() < 0.05:
                emotion = random.choice(['disgust', 'contempt', 'shame', 'guilt'])

            # 创建情感分析结果
            emotion_analysis = {
                'sentiment': 'POSITIVE' if emotion in ['joy', 'love', 'surprise'] else 'NEGATIVE',
                'sentiment_score': random.uniform(0.7, 0.95),
                'emotion': emotion,
                'emotion_score': random.uniform(0.7, 0.95)
            }

            # 添加到测试数据
            test_data.append({
                'book': book,
                'paragraph_id': i,
                'content': f"Test paragraph {i} with {emotion} emotion.",
                'emotion_analysis': emotion_analysis
            })

    return pd.DataFrame(test_data)

# 修复的可视化函数
def visualize_book_emotions_fixed(df):
    """Visualize emotion distribution across books with fixed labels"""
    # 准备数据 - 确保情感数据是直接从emotion_analysis字典中提取
    emotion_data = []
    for _, row in df.iterrows():
        book = row['book'].replace('.txt', '')
        emotion = row['emotion_analysis']['emotion']
        emotion_data.append({'book': book, 'emotion': emotion})

    emotion_df = pd.DataFrame(emotion_data)

    # 统计每本书中的情感总数
    book_totals = emotion_df.groupby('book').size()

    # 获取所有唯一的情感标签并排序
    unique_emotions = sorted(emotion_df['emotion'].unique())

    # 如果情感类型太多（超过7种），只保留最常见的6种，其余归为"Others"
    if len(unique_emotions) > 7:
        # 计算每种情感的总频率
        emotion_counts = emotion_df['emotion'].value_counts()
        top_emotions = emotion_counts.nlargest(6).index.tolist()

        # 将非主要情感标为"Others"
        emotion_df['emotion'] = emotion_df['emotion'].apply(
            lambda x: x if x in top_emotions else 'Others')

    # 创建一个颜色映射，确保每种情感有一个一致的颜色
    # 使用易于区分的颜色方案
    color_map = {
        'joy': '#FFD700',        # 金色
        'sadness': '#1E90FF',    # 道奇蓝
        'anger': '#FF4500',      # 橙红色
        'fear': '#800080',       # 紫色
        'love': '#FF69B4',       # 粉红色
        'surprise': '#00FF7F',   # 春绿色
        'Others': '#A9A9A9'      # 深灰色
    }

    # 添加额外的情感颜色
    extra_colors = {
        'disgust': '#8B4513',    # 棕色
        'contempt': '#4682B4',   # 钢蓝色
        'shame': '#CD5C5C',      # 印度红
        'guilt': '#6A5ACD'       # 板岩蓝
    }
    color_map.update(extra_colors)

    # 计算情感百分比
    emotion_counts = emotion_df.groupby(['book', 'emotion']).size().unstack().fillna(0)

    # 确保所有列都存在，如果没有则添加为0
    all_emotions = sorted(emotion_df['emotion'].unique())
    for emotion in all_emotions:
        if emotion not in emotion_counts.columns:
            emotion_counts[emotion] = 0

    # 将计数转换为百分比
    emotion_percentages = emotion_counts.copy()
    for col in emotion_counts.columns:
        emotion_percentages[col] = emotion_counts[col] / emotion_counts.sum(axis=1) * 100

    # 创建堆叠条形图
    plt.figure(figsize=(15, 10))

    # 获取排序后的情感类型列表（确保Others在最后）
    ordered_emotions = sorted([e for e in emotion_percentages.columns if e != 'Others'])
    if 'Others' in emotion_percentages.columns:
        ordered_emotions.append('Others')

    # 提取颜色列表，确保顺序与情感列表匹配
    colors = [color_map.get(emotion, '#333333') for emotion in ordered_emotions]

    # 创建堆叠条形图，使用排序后的情感和对应的颜色
    ax = emotion_percentages[ordered_emotions].plot(
        kind='bar',
        stacked=True,
        figsize=(15, 10),
        color=colors
    )

    # 设置图表标题和标签
    plt.title('Emotion Distribution Across Toni Morrison\'s Works', fontsize=16)
    plt.ylabel('Percentage of Paragraphs (%)', fontsize=14)
    plt.xlabel('Book Title', fontsize=14)
    plt.xticks(rotation=45, ha='right', fontsize=12)
    plt.yticks(fontsize=12)

    # 确保y轴最大值不超过100%
    plt.ylim(0, 105)

    # 添加网格线
    plt.grid(axis='y', linestyle='--', alpha=0.3)

    # 添加图例，确保情感标签清晰可见
    plt.legend(title='Emotion Type', title_fontsize=14, fontsize=12)

    # 添加样本大小标签
    for i, book in enumerate(emotion_percentages.index):
        book_total = book_totals[book]
        plt.text(i, 5, f'n={book_total}', ha='center', fontsize=10, color='black',
                 bbox=dict(facecolor='white', alpha=0.7, boxstyle='round,pad=0.2'))

    plt.tight_layout()

    return emotion_percentages

# 创建测试数据并运行修复的可视化函数
def run_fixed_visualization_test():
    # 创建测试数据
    print("Creating test data...")
    test_df = create_test_data()
    print(f"Created test dataset with {len(test_df)} paragraphs across {test_df['book'].nunique()} books")

    # 打印示例数据，验证情感标签
    print("\nSample emotion data:")
    sample_emotions = [row['emotion_analysis']['emotion'] for _, row in test_df.head(10).iterrows()]
    print(sample_emotions)

    # 运行修复后的可视化函数
    print("\nGenerating visualization with fixed labels...")
    emotion_percentages = visualize_book_emotions_fixed(test_df)

    # 显示图表
    plt.savefig('fixed_emotion_distribution.png')
    plt.show()

    print("Test completed. Fixed visualization has been displayed and saved as 'fixed_emotion_distribution.png'")

    # 输出数据统计
    print("\nEmotion distribution percentages:")
    print(emotion_percentages.round(2))

# 运行修复后的测试
run_fixed_visualization_test()

def test_english_visualization():
    """Test English visualization functions"""
    print("Testing English visualization...")

    # 创建模拟数据
    emotions = ['anger', 'fear', 'joy', 'love', 'sadness', 'surprise']

    # 生成随机数据
    np.random.seed(42)
    data = []
    book_name = "Test Book.txt"

    for i in range(50):
        emotion = np.random.choice(emotions)
        score = np.random.uniform(0.4, 1.0)

        data.append({
            'book': book_name,
            'paragraph_id': i,
            'content': f"This is test paragraph {i}",
            'emotion_analysis': {'emotion': emotion, 'emotion_score': score}
        })

    df = pd.DataFrame(data)

    # 测试情感流动可视化
    print("Testing emotion flow visualization...")
    flow_result = visualize_emotion_flow(df, book_name)
    plt.savefig('test_emotion_flow.png')
    plt.close()

    print("Visualization test complete! Check 'test_emotion_flow.png' to verify English labels.")
    return "Test completed successfully"

# 运行测试
test_result = test_english_visualization()
print(test_result)